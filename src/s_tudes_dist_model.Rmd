---
title: "s_tudes_dist_model"
author: "Leonardo Feitosa"
date: "15/01/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
library(vegan)
library(raster)
library(dismo)
library(maps)
library(kernlab)
library(vegan)
library(rJava)
library(maptools)
library(sdmpredictors)
library(usdm)
library(googlesheets4)
```

## Read in the data

```{r}
# Load occurrence data

#GBIF
# stud_data_gbif <- read.csv(here::here("data", "occurrences", "s_tudes_occurrences_raw_gbif.csv"), sep = ";") %>% 
#   clean_names() %>% 
#   dplyr::rename(long = decimal_longitude,
#          lat = decimal_latitude) %>% 
#   mutate(source = case_when(
#     species == "Sphyrna tudes" ~ "GBIF"
#   )) 


#OBIS
# stud_data_obis <- read.csv(here::here("data","occurrences", "obis_raw.csv"), sep = ";")  %>% 
#   clean_names() %>% 
#   dplyr::rename(long = decimallongitude,
#          lat = decimallatitude) %>% 
#   mutate(source = case_when(
#     scientificname == "Sphyrna tudes" ~ "OBIS"
#   ))

#Fish net
# stud_data_fishnet <- read.csv(here::here("data","occurrences", "fish_net_2_raw.csv"), sep = ";")  %>% 
#   clean_names() %>% 
#   dplyr::rename(long = longitude,
#          lat = latitude) %>% 
#   mutate(source = case_when(
#     scientific_name == "Sphyrna tudes" ~ "FISHNET"
#   ))

# Map data
world_countries <- read_sf(here::here("data", "world_countries", "World_Countries.shp"))

# read whole occurrence data 
whole_occur_data_final <- read.csv(here::here("data", "occurrences", "occurrence_data.csv"), sep = ";") %>%  
  dplyr::select(long, lat)
``` 
## Load env layers

```{r}
env_layers <- list.files(here::here("data", "raster_layers", "present"), pattern =".tif", full.names = TRUE)
```

```{r}
#read in the data in .txt
ocor <- read.table(here::here("data", "occurrences", "occurrence_data.txt"), h = T)
```


```{r}
# Create new dataset with only lat and long
# gbif_subset <- stud_data_gbif %>% 
#   dplyr::select(source, long, lat) %>% 
#   mutate_at(c(2,3), as.numeric)
# 
# obis_subset <- stud_data_obis %>% 
#   dplyr::select(source, long, lat)
# 
# fish_subset <- stud_data_fishnet %>% 
#   dplyr::select(source, long, lat) %>% 
#   mutate_at(c(2,3), as.numeric)
# 
# geo_data_whole <- join_all(list(gbif_subset, obis_subset, fish_subset), type = "full") %>% 
#   drop_na()
# 
# write_csv(geo_data_whole, path = here::here("data", "occurrences", "occurrence_data.csv"), col_names = TRUE)
```

```{r, fig.width=10, fig.height=10}
# Plot occurrences in an interactive map using tmap
ggplot() +
  geom_sf(data = world_countries,
          color = "black") +
  geom_point(data = whole_occur_data_final,
             aes(x = long, y = lat, color = source)) +
  coord_sf()

ggsave(here::here("outputs", "occurrence_map.png"), height = 8, width = 10)
```




## Clean and wrangle data

```{r}
# Select useful variables from raw data
# gcir_clean <- gcir_data %>% 
#   rename(lat = decimal_latitude,
#          long = decimal_longitude) %>% 
#   dplyr::select(species, country_code, basis_of_record, institution_code, day, month, year, identified_by, lat, long)
#   
# # Create a dataset with occurrences only 
# gcir_ocur <- gcir_clean %>% 
#   dplyr::select(long, lat)
# 
# # Counts of observations from countries
# gcir_counts <- gcir_clean %>% 
#   mutate(countries = case_when(
#     country_code %in% c("BM") ~ "Bermuda",
#     country_code %in% c("BZ") ~ "Belize",
#     country_code %in% c("CO") ~ "Colombia",
#     country_code %in% c("BR") ~ "Brazil",
#     country_code %in% c("BQ") ~ "Sint Eustatius",
#     country_code %in% c("BS") ~ "Bahamas",
#     country_code %in% c("MX") ~ "Mexico",
#     country_code %in% c("US") ~ "United States of America",
#     country_code %in% c("CR") ~ "Costa Rica",
#     country_code %in% c("GF") ~ "French Guyana",
#     country_code %in% c("PA") ~ "Panama",
#     country_code %in% c("JM") ~ "Jamaica",
#     country_code %in% c("EC") ~ "Ecuador",
#     )) %>% 
#   count(countries, institution_code)
# 
# #Create finalized table of occurrence counts
# gcir_counts %>% 
#   kable(col.names = c("Country",
#                       "Institution",
#                       "n"),
#         caption = "Occurrence counts retrieved from GBIF by country and institutions") %>% 
#   kable_classic(bootstrap_options = "striped", full_width = F)
```

## loading biooracle data

```{r}
# Check for layer codes from Bio-ORACLE
list_layers(c("Bio-ORACLE", monthly = F, marine = TRUE))$layer_code

# Load selected layers based on knowledge about the species biology
env_layers <- load_layers(c("BO21_salinitymean_bdmin",
                            "BO21_salinitymean_bdmin",
                            "BO21_salinitymean_ss",
                            "BO21_salinityrange_ss",
                            "BO21_tempmean_ss",
                            "BO21_temprange_ss",
                            "BO21_tempmean_bdmin",
                            "BO21_tempmean_bdmin",
                            "BO21_chlomean_ss",
                            "BO21_chlorange_ss",
                            "BO21_dissoxmean_bdmin",
                            "BO21_dissoxmean_bdmin",
                            "BO21_dissoxmean_ss",
                            "BO21_dissoxrange_ss",
                            "BO21_lightbotmean_bdmin",
                            "BO21_lightbotmean_bdmin",
                            "BO21_curvelmean_ss",
                            "BO21_curvelrange_ss",
                            "BO21_curvelmean_bdmin",
                            "BO21_curvelrange_bdmin",
                            "BO_cloudmean"))

# Layers from the future
list_layers_future(terrestrial = FALSE)

env_layers_future <- load_layers(c("BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinityrange_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax",
                                   "BO21_RCP45_2050_salinitymean_bdmax"))
```


# Wrangling layer data

```{r}
predictors <- lapply(env_layers, raster)

predictors <- stack(predictors)
#determina as coordenadas para delimitar a extensao do mapa abaixo
#coordenadas para analise em menor escala: (-80,-35,-10,20)
map_extent <- extent(-120, 0, -80, 50) 

#define a extensao (recorta a America do Sul)
predictors <- crop(predictors, map_extent) 

```

```{r}
#seleciona o plot para uma determinada variavel
plot(predictors[[5]])

#coloca os contornos no mapa
map(add=T)

#inserir pontos de ocorrencia no mapa
points(ocor, pch=20) 

```


## Assembling the models

```{r}
# número de repetições para rodar os modelos
repeticao = 20

# extrai pontos de ocorrencias com as variaveis climaticas OBS: Longitude primeiro e depois latitude
ocor.val <- raster::extract(predictors, ocor, cell = T)

# identificar células duplicadas
id.dup <- duplicated(ocor.val[,"cells"])

#cbind junta as colunas de pontos de ocorrencia com as variaveis climaticas
ocor <- cbind(ocor, ocor.val[,-1])

ocor <- ocor[which(id.dup == FALSE),]

ocor <- na.omit(ocor)
```


## Selecting variables

```{r}
# checar correlacao das variaveis
variables <- ocor[,3:12]

correlation <- (cor(variables)> 0.7)*1

# calling package "usdm" to calculate collinearity between environmental variables
library(usdm)

usdm::vif(variables)

# variables that should be excluded based on vif >= 10
variables2 <- vifstep(variables, th = 10) 
variables2 


#Transform correlation matrix into a df
#correlation_df <- as.data.frame(correlation)

#write_csv(correlation_df, path = here::here("data", "raster_layers", "present_env_layers_correlation_mtx2.csv"), col_names = T)
```

- List of rasters to remove due to high correlation:
benthic Current velocity range, light at bottom range, benthic silicate mean, surface current velocity range, surface iron range, benthic chlorophil range, benthic chlorophil mean, surface dissolved oxygen range, removed all range variables and mean benthic temperature 


### Background points

```{r}
bg <- randomPoints(predictors, nrow(ocor), ext = map_extent)

# extracts cells chosen for absences
back <- extract(predictors, bg)

# Combines background coordinate points and extracted cells 
back <- cbind(bg, back)

#Ploting pseudo-absence points (background)
#points(bg, pch = 20, col = "red")


data <- prepareData(x = predictors, p = ocor[, 1:2], b = back[, 1:2])
```


## Assembling models

## Creating objects to store results 
```{r}
bioclim0k <-gower0k<-maha0k<-maxent0k<-SVM0k<-GLM0k<-stack()

bioclim.e <-gower.e<-maha.e<-maxent.e<-SVM.e<-GLM.e<-NULL

bioclim.t <-gower.t<-maha.t<-maxent.t<-SVM.t<-GLM.t<-NULL
```


# Model loop
```{r}
for(i in 1:20){
  id.treino<-sample(1:nrow(ocor),round(0.75*nrow(ocor),0))  ###0.75 ? pra pegar 75% dos pontos de ocorrencia pra treino, o round ? s? pra nao dar numero quebrado
  treino<-prepareData(x = predictors, p = ocor[id.treino,1:2], b = back[id.treino,1:2])  ##o id.treino ta falando que ? pra pegar s? as linhas do id.treino
  teste<-prepareData(x = predictors, p = ocor[-id.treino,1:2], b = back[-id.treino,1:2])  ##aqui o -id.treino ? pra tirar os usados no id.treino
  
  
  #1) Bioclim
  
  ####Ajustando o modelo
  bioclim.modelo<-bioclim(treino[treino[,"pb"]==1,-1]) ##aqui ta falando pra roda s? a coluna de treino que tenha 1(presen?a), o -1 da coluna ? pra tira a pb
  #plot(bioclim.modelo)
  #response(bioclim.modelo)
  #fazendo predi??es
  bioclim0k<-stack(bioclim0k, predict(object=bioclim.modelo, x = predictors, progress='text'))  ###objto ? uma classe bioclim, maxent etc,e x ? o modelo clim?tico (e.g. 21k, 0 e rcp)
  #plot(bioclim0k)
  #map(add=T)
  #plot(bioclim0k>0.2) ###aqui ? prar binarizar, coloca o threshold para transformar s? em presen?a/ausencia
  #map(add=T)
  
  ###Avaliando modelo
  bioclim.eval <- evaluate(p=teste[teste[,"pb"]==1,-1], a=teste[teste[,"pb"]==0,-1], model=bioclim.modelo)
  bioclim.e <- c(bioclim.e, bioclim.eval@auc)
  bioclim.t <- c(bioclim.t, threshold(bioclim.eval, "spec_sens"))
  #density(bioclim.eval)
  #boxplot(bioclim.eval, col = c("blue","red"))
  #threshold(bioclim.eval) ##o valor dos threshold que maximiza, sensibilidade s?o as taxas de presen?a que o modelo previu como presen?a, e a especificidade as ausencias que s?o ausencias
  
  #2) Gower
  ####Ajustando o modelo
  gower.modelo <- domain(treino[treino[,"pb"]==1,-1]) ##aqui ta falando pra roda s? a coluna de treino que tenha 1(presen?a), o -1 da coluna ? pra tira a pb
  
  #fazendo predi??es
  gower0k <- stack(gower0k, predict(object=gower.modelo, x = predictors, progress='text'))  ###objto ? uma classe bioclim, maxent etc,e x ? o modelo clim?tico (e.g. 21k, 0 e rcp)
  
  #plot(gower0k)
  #map(add=T)
  
  ###Avaliando modelo
  gower.eval <- evaluate(p=teste[teste[,"pb"]==1,-1], a=teste[teste[,"pb"]==0,-1], model=gower.modelo)
  gower.e <- c(gower.e, gower.eval@auc)
  gower.t <- c(gower.t, threshold(gower.eval, "spec_sens"))
  #response(gower.modelo)
  
  #3) Mahalanobis
  ####Ajustando o modelo
  maha.modelo <- mahal(treino[treino[,"pb"]==1,-1]) ##aqui ta falando pra roda s? a coluna de treino que tenha 1(presen?a), o -1 da coluna ? pra tira a pb
  #fazendo predi??es
  maha0k <- stack(maha0k, predict(object=maha.modelo, x = predictors, progress='text'))  ###objto ? uma classe bioclim, maxent etc,e x ? o modelo clim?tico (e.g. 21k, 0 e rcp)
  #plot(maha0k)
  #map(add=T)
  
  ###Avaliando modelo
  maha.eval <- evaluate(p=teste[teste[,"pb"]==1,-1], a=teste[teste[,"pb"]==0,-1], model=maha.modelo)
  maha.e <- c(maha.e, maha.eval@auc)
  maha.t <- c(maha.t, threshold(maha.eval, "spec_sens"))
  
  #4) Maxent
  ####Ajustando o modelo
  library(rJava)#Instala e depois roda esse pacote (precisa do Java pro Maxent)
  system("java -version") #para saber a vers?o do Java  que tem no seu pc
  Sys.setenv(NOAWT=TRUE)
  
  maxent.modelo <- maxent(x=treino[,-1], p=treino[,1]) ###na primeira coluna indica presen?a e ausencia, e nas outras colunas os valores de variaveis ambientais.
  #fazendo predi??es
  maxent0k <- stack(maxent0k,predict(object=maxent.modelo, x = predictors, progress='text' ))  ###objto ? uma classe bioclim, maxent etc,e x ? o modelo clim?tico (e.g. 21k, 0 e rcp)
  #plot(maxent0k)
  
  ###Avaliando modelo
  maxent.eval <- evaluate(p=teste[teste[,"pb"]==1,-1], a=teste[teste[,"pb"]==0,-1], model=maxent.modelo)
  maxent.e <- c(maxent.e, maxent.eval@auc)
  maxent.t <- c(maxent.t, threshold(maxent.eval, "spec_sens"))
  
  
} #fecha for i
```

### Building the rasters

```{r}
# BioClim
writeRaster(bioclim0k, "bioclim0k.bil", format = "EHdr", overwrite = T)

#Gower
writeRaster(gower0k, "gower0k.bil", format = "EHdr", overwrite = T)

# Maha
writeRaster(maha0k, "maha0k.bil", format = "EHdr",overwrite = T)

# Maxent
writeRaster(maxent0k, "maxent0k.bil", format = "EHdr", overwrite = T)

# Write AUC table for all models
write.table(data.frame(bioclim = bioclim.e, gower = gower.e, maha = maha.e,maxent = maxent.e),
            here::here("data", "outputs", "tests_present", "AUC_comparison_pres_fut.txt"), sep = "\t", row.names = F)
write.table(data.frame(bioclim = bioclim.t, gower = gower.t, maha = maha.t,maxent = maxent.t),
            here::here("data", "outputs", "tests_present", "Thresh_comparison_pres_fut.txt"), sep = "\t", row.names = F)
```

# Part 2

```{r}
# reading the table with AUC values for each model
auc <- read.table(here::here("data", "outputs", "tests_present", "AUC_comparison_pres_fut.txt"), h = T)

# Gensemble
gensemble <- vector(mode = "list", length = 1)
```


### BIOCLIM
```{r}
bioclima <- stack("bioclim0k.bil")[[which(auc[, "bioclim"]>= 0.7)]]  ###which ? para selecionar somente os modelos com auc maior que 0.7

bioclima.auc <- auc[which(auc[,"bioclim"]>= 0.7), "bioclim"] ##esse ultimo bioclim s?o os stacks
bioclima.metodo <- rep("bioclim", nlayers(bioclima)) ##repete esse bioclim o numero dele layers(60) do bioclim.
```

### GOWER

```{r}
gowera <- stack("gower0k.bil")[[which(auc[, "gower"]>= 0.7)]]  ###which ? para selecionar somente os modelos com auc maior que 0.7

gowera.auc <- auc[which(auc[,"gower"]>= 0.7), "gower"] ##esse ultimo gower s?o os stacks
gowera.metodo <- rep("gower", nlayers(gowera)) ##repete esse gower o numero dele layers(60) do gower.
```

### MAHA

```{r}
mahaa <- stack("maha0k.bil")[[which(auc[, "maha"]>= 0.7)]]  ###which ? para selecionar somente os modelos com auc maior que 0.7

mahaa.auc <- auc[which(auc[, "maha"]>= 0.7), "maha"] ##esse ultimo maha s?o os stacks
mahaa.metodo <- rep("maha", nlayers(mahaa)) ##repete esse maha o numero dele layers do maha.
```

### MAXENT

```{r}
maxenta <- stack("maxent0k.bil")[[which(auc[, "maxent"]>= 0.7)]]  ###which ? para selecionar somente os modelos com auc maior que 0.7

maxenta.auc <- auc[which(auc[, "maxent"]>= 0.7), "maxent"] ##esse ultimo maxent s?o os stacks
maxenta.metodo <- rep("maxent", nlayers(maxenta)) ##repete esse maxent o numero dele layers(60) do maxent.
```

## Standardizing adequatability

```{r}
# Stardizing adequatability values between models

bioclim.val<-na.omit(values(bioclima))
bioclim.pad<- decostand(bioclim.val, "standardize", 2)

gower.val<-na.omit(values(gowera))
gower.pad<-decostand(gower.val, "standardize", 2)

maha.val<-na.omit(values(mahaa))
maha.pad<-decostand(maha.val, "standardize", 2)

maxent.val<-na.omit(values(maxenta))
maxent.pad<-decostand(maxent.val, "standardize", 2)
```


## Calculating ensemble 
```{r}
suit <- data.frame(bioclim.pad,gower.pad,maha.pad,maxent.pad) ##Aqui coloca os valores padronizados em um dataframe
auc <- c(bioclima.auc,gowera.auc,mahaa.auc,maxenta.auc) ##aqui os valores de auc

ensemble <- apply(suit,1,function(x)sum(x*auc)/sum(auc)) #Aqui faz o ensemble, a gente ve o quanto cada modelo contribui pro mapa com base nos seus valores de auc, que seria a media ponderada pelo auc de cada modelo

ensemble <- data.frame(na.omit(data.frame(xyFromCell(bioclima,1:ncell(bioclima)), values(bioclima)))[,c("x","y")], ensemble)

ensemble <- rasterFromXYZ(ensemble) ##Aqui faz um raster com os ensemble

coordsp <- ocor
valm <- extract(ensemble, coordsp[, c("long", "lat")], cell = T) ##pega os valores de adequabilidade ambiental preditos pelo ensemble nos pontos de ocorr?ncia

valm2 <- quantile(valm[,2],.05, na.rm = T) ##aqui se usa um quantil pra binarizar o mapa, normalmente o pessoa usa 0.5.Isso que dizer que s? os locais que tem os valores de adequabilidade maiores que o quntil de 5%
#de todos os dados de ocorr?ncia ? que v?o ser binarizados pra ?rea adequada. O valor ele ? regra de polegar, tipo o 05 do valor de p, o pessoal normalmente usa esse valor de quantil ai, mas vc pode aumentar
#ou diminuir se quiser

# Making the map binary
gensemble[[1]] <- ensemble>= valm2
```


## Writing final tiff files


```{r}
# Tif 1
writeRaster(x = gensemble[[1]], 
            filename = file.path(here::here("data", "outputs", "present","ensemble_stud_binary_present_comparison.tif"), sep=""),
            format = 'GTiff', overwrite=T)
plot(ensemble)
writeRaster(x = ensemble, 
            filename = file.path(here::here("data", "outputs", "present", "ensemble_stud_prob_present_comparison.tif"), sep=""), 
            format = 'GTiff', overwrite=T)

tiff(file="ensembled_binary_pres_comparison.tiff", width = 3200, height = 3200, res = 400, compression = "lzw")
plot(gensemble[[1]])
points(ocor, pch=20) 
map(add=T)
dev.off()

tiff(file="ensembled_prob_pres_comparison.tiff", width = 3200, height = 3200, res = 400, compression = "lzw")
plot(ensemble)
points(ocor, pch=20) #inserir pontos de ocorr?ncia no mapa
map(add=T)
dev.off()

e <- extent(-80,-30,-10,20) 
fig.menor <- crop(ensemble, e)
tiff(file="ensemble_prob_smaller_pres_comparison.tiff", width = 3200, height = 3200, res = 400, compression = "lzw")
plot(fig.menor)
points(ocor, pch=20) #inserir pontos de ocorr?ncia no mapa
map(add=T)
dev.off()

```


